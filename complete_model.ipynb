{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import pandas as pd\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, datasets\n",
    "from PIL import Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "image_dir = \"data/naodevils/images\"\n",
    "data_dir = \"data/naodevils/spqr_autolabel_and_manual_train_patchified.csv\"\n",
    "val_dir = \"data/naodevils/spqr_manual_val_patchified.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from math import isnan\n",
    "class BallDataset(Dataset):\n",
    "    def __init__(self, data_dir, images_dir, transform=None):\n",
    "        self.data_dir = data_dir\n",
    "        self.images_dir = images_dir\n",
    "        self.transform = transform\n",
    "        self.df = pd.read_csv(data_dir)\n",
    "\n",
    "        self.dimension = transform.transforms[0].size[0]\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        row = self.df.iloc[idx]\n",
    "        img = Image.open(os.path.join(self.images_dir, row[\"image\"])).convert(\"L\")  # Convert to grayscale\n",
    "        patch_dim = (row[\"patch_x\"], row[\"patch_y\"], row[\"patch_x\"] + row[\"patch_size\"], row[\"patch_y\"] + row[\"patch_size\"])\n",
    "        patch = img.crop(patch_dim)\n",
    "        resize_ratio = self.dimension / row[\"patch_size\"]\n",
    "        x = (row[\"center_x\"] - row[\"patch_x\"]) * resize_ratio if row[\"patch_contains_ball\"] else float('nan')\n",
    "        y = (row[\"center_y\"] - row[\"patch_y\"]) * resize_ratio if row[\"patch_contains_ball\"] else float('nan')\n",
    "        r = row[\"radius\"] * resize_ratio if row[\"patch_contains_ball\"] else float('nan')\n",
    "        if self.transform:\n",
    "            patch = self.transform(patch)\n",
    "        patch = patch * 255.0\n",
    "\n",
    "\n",
    "        assert isnan(x) or x < 32, (row[\"patch_x\"], row[\"patch_size\"], row[\"center_x\"], x)\n",
    "\n",
    "        return patch, row[\"patch_contains_ball\"], {\"x\":x, \"y\":y, \"r\":r}\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((32, 32)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from matplotlib.patches import Circle\n",
    "\n",
    "dataset = BallDataset(data_dir, image_dir, transform)\n",
    "validation = BallDataset(val_dir, image_dir, transform)\n",
    "\n",
    "batch_size = 256\n",
    "data_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "validation_loader = DataLoader(validation, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "sample = next(iter(data_loader))\n",
    "\n",
    "num_images = 5\n",
    "\n",
    "ig, axes = plt.subplots(2, num_images, figsize=(num_images * 3, 3))\n",
    "\n",
    "for i in range(num_images):\n",
    "    axes[0, i].imshow(sample[0][i][0], cmap='gray')\n",
    "    if sample[1][i]:\n",
    "        c = Circle((sample[2][\"x\"][i].item(),sample[2][\"y\"][i].item()), sample[2][\"r\"][i].item())\n",
    "        c.set_facecolor((1.0,0.,0.,0.4))\n",
    "        axes[0, i].add_patch(c)\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].text(0.5, 0, f'Contains Ball: {sample[1][i]}', horizontalalignment='center')  # Add text under each image\n",
    "    axes[1, i].axis('off')  # Turn off axis for text\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "class DepthwiseSeparableConv(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, use_residual=False):\n",
    "        super(DepthwiseSeparableConv, self).__init__()\n",
    "        self.depthwise = nn.Conv2d(in_channels, in_channels, kernel_size=3, stride=stride, padding=1, groups=in_channels, bias=False)\n",
    "        self.pointwise = nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=1, padding=0, bias=False)\n",
    "        self.bn = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.use_residual = use_residual\n",
    "\n",
    "    def forward(self, x):\n",
    "        z = self.depthwise(x)\n",
    "        z = self.pointwise(z)\n",
    "        z = self.bn(z)\n",
    "        z = self.relu(z) + x if self.use_residual else self.relu(z)\n",
    "        return z\n",
    "\n",
    "\n",
    "class BallPerceptor(nn.Module):\n",
    "    def __init__(self, backbone_size = 9):\n",
    "        super(BallPerceptor, self).__init__()\n",
    "        \n",
    "        self.conv1 = DepthwiseSeparableConv(1, 8, stride=1)\n",
    "        self.conv2 = DepthwiseSeparableConv(8, 16, stride=1)\n",
    "        self.conv3 = DepthwiseSeparableConv(16, 32, stride=1)\n",
    "        \n",
    "        backbone_layers = []\n",
    "        for _ in range(backbone_size):\n",
    "            backbone_layers.append(DepthwiseSeparableConv(32, 32, stride=1,use_residual=True))\n",
    "\n",
    "        self.backbone = nn.Sequential(*backbone_layers)\n",
    "\n",
    "        self.pool = nn.MaxPool2d(2, 2)\n",
    " \n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(32 * 4 * 4, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 1),\n",
    "        )\n",
    "        self.segmenter = nn.Sequential(\n",
    "            nn.Linear(32 * 4 * 4, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 3), # x, y, r\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.pool(self.conv1(x))\n",
    "        x = self.pool(self.conv2(x))\n",
    "        x = self.pool(self.conv3(x))\n",
    "        \n",
    "        x = self.backbone(x)\n",
    "\n",
    "        feature_map = x.view(-1, 32 * 4 * 4)\n",
    "\n",
    "        classification = self.classifier(feature_map) if self.training else torch.sigmoid(self.classifier(feature_map))\n",
    "        segmentation = self.segmenter(feature_map)\n",
    "        return classification, segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.nn.modules.loss import _Loss\n",
    "\n",
    "class Circular_DIoU(_Loss):\n",
    "    def __init__(self, size_average=None, reduce=None, reduction: str = 'mean') -> None:\n",
    "        super().__init__(size_average, reduce, reduction)\n",
    "\n",
    "    def intersectionArea(self, X1, Y1, R1, X2, Y2, R2):\n",
    "        d = torch.sqrt(((X2 - X1) * (X2 - X1)) + ((Y2 - Y1) * (Y2 - Y1)))\n",
    "\n",
    "        # Case 1: no overlap \n",
    "        mask_1 = d > R1 + R2\n",
    "\n",
    "        # Case 2: One circle is fully within the other\n",
    "        mask_2 = ( d <= (R1 - R2) ) & ( R1 >= R2 )\n",
    "        mask_3 = ( d <= (R2 - R1) ) & ( R2 > R1 )\n",
    "\n",
    "        # Case 3: Partial overlap\n",
    "        mask_else = ~(mask_1 | mask_2 | mask_3)\n",
    "\n",
    "        intersection_area = torch.zeros_like(d, dtype=torch.float32)\n",
    "\n",
    "        intersection_area[mask_2] = torch.pi * R2[mask_2] * R2[mask_2]\n",
    "        intersection_area[mask_3] = torch.pi * R1[mask_3] * R1[mask_3]\n",
    "\n",
    "        alpha = torch.acos(((R1[mask_else] * R1[mask_else]) + (d[mask_else] * d[mask_else]) - (R2[mask_else] * R2[mask_else])) / (2 * R1[mask_else] * d[mask_else])) * 2\n",
    "        beta = torch.acos(((R2[mask_else] * R2[mask_else]) + (d[mask_else] * d[mask_else]) - (R1[mask_else] * R1[mask_else])) / (2 * R2[mask_else] * d[mask_else])) * 2\n",
    "        \n",
    "        a1 = (0.5 * beta * R2[mask_else] * R2[mask_else] ) - (0.5 * R2[mask_else] * R2[mask_else] * torch.sin(beta))\n",
    "        a2 = (0.5 * alpha * R1[mask_else] * R1[mask_else]) - (0.5 * R1[mask_else] * R1[mask_else] * torch.sin(alpha))\n",
    "\n",
    "        intersection_area[mask_else] = a1 + a2\n",
    "\n",
    "        return intersection_area\n",
    "\n",
    "    def forward(self, input, target):\n",
    "        a1 = torch.pi * torch.pow(input[:,2], 2)\n",
    "        a2 = torch.pi * torch.pow(target[:,2], 2)\n",
    "\n",
    "        a1inta2 = self.intersectionArea(input[:,0], input[:,1], input[:,2], target[:,0], target[:,1], target[:,2])\n",
    "\n",
    "        a1una2 = a1 + a2 - a1inta2\n",
    "\n",
    "        center_diff = input[:,:2] - target[:,:2]\n",
    "\n",
    "        center_dist = torch.norm(center_diff, dim=-1)\n",
    "        D = torch.pow(center_dist, 2)/torch.pow(center_dist + input[:,2] + target[:,2], 2)\n",
    "\n",
    "        DIoU = 1 - a1inta2/a1una2 + D\n",
    "\n",
    "        if self.reduction == 'mean':\n",
    "            return DIoU.mean()\n",
    "        elif self.reduction == 'sum':\n",
    "            return DIoU.sum()\n",
    "        else:\n",
    "            return DIoU\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[0.1031]], grad_fn=<AddmmBackward0>), tensor([[ 0.1560, -0.0350, -0.5180]], grad_fn=<AddmmBackward0>))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "BallPerceptor(\n",
       "  (conv1): DepthwiseSeparableConv(\n",
       "    (depthwise): Conv2d(1, 1, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (pointwise): Conv2d(1, 8, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv2): DepthwiseSeparableConv(\n",
       "    (depthwise): Conv2d(8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=8, bias=False)\n",
       "    (pointwise): Conv2d(8, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (conv3): DepthwiseSeparableConv(\n",
       "    (depthwise): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "    (pointwise): Conv2d(16, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU()\n",
       "  )\n",
       "  (backbone): Sequential(\n",
       "    (0): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (1): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (2): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (3): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (4): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (5): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (6): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (7): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "    (8): DepthwiseSeparableConv(\n",
       "      (depthwise): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=32, bias=False)\n",
       "      (pointwise): Conv2d(32, 32, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "      (bn): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      (relu): ReLU()\n",
       "    )\n",
       "  )\n",
       "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "  (classifier): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "  )\n",
       "  (segmenter): Sequential(\n",
       "    (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Linear(in_features=512, out_features=128, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=128, out_features=32, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=32, out_features=3, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = BallPerceptor()\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "p_weight = torch.tensor([0.85]).to(device)\n",
    "classification_criterion = nn.BCEWithLogitsLoss(pos_weight=p_weight)\n",
    "segmentation_criterion = Circular_DIoU()\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.0001)\n",
    "\n",
    "num_epochs = 5\n",
    "log_rate = 100\n",
    "eval_rate = 300\n",
    "\n",
    "r = torch.rand((1, 1, 32, 32))\n",
    "\n",
    "print(model(r))\n",
    "\n",
    "model.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "#best_loss = float(\"inf\")\n",
    "best_loss = 2.883556\n",
    "PATH = \"strong.pt\"\n",
    "\n",
    "if os.path.exists(PATH):\n",
    "    model.load_state_dict(torch.load(PATH))\n",
    "    model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "@torch.no_grad()\n",
    "def validate(model: nn.Module, detection_weight: float, best_loss: float):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    val_loss = 0\n",
    "    all_labels = []\n",
    "    all_predictions = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for data in validation_loader:\n",
    "            images, labels = data[0].to(device), data[1].float().to(device)\n",
    "            segmentation_gt = torch.stack((data[2][\"x\"], data[2][\"y\"], data[2][\"r\"]), dim=1).to(device).to(torch.float)\n",
    "            classification_mask = labels == 1.\n",
    "\n",
    "            classification, segmentation = model(images)\n",
    "\n",
    "            val_loss += classification_criterion(classification, labels.unsqueeze(1))                    \n",
    "            val_loss += detection_weight * segmentation_criterion(segmentation[classification_mask], segmentation_gt[classification_mask])\n",
    "\n",
    "            predicted = torch.round(classification)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels.unsqueeze(1)).sum().item()\n",
    "\n",
    "            all_labels.extend(labels.cpu().numpy())\n",
    "            all_predictions.extend(predicted.cpu().numpy())\n",
    "\n",
    "    model.train()\n",
    "    accuracy = 100 * correct / total\n",
    "    val_loss /= total / batch_size\n",
    "\n",
    "    # Compute F1-score\n",
    "    f1 = f1_score(all_labels, all_predictions, average='binary')\n",
    "\n",
    "    if val_loss < best_loss:\n",
    "        best_loss = val_loss\n",
    "        torch.save(model.state_dict(), PATH)\n",
    "\n",
    "    model.train()\n",
    "    return val_loss, accuracy, f1*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5269 [03:45<3:14:58,  2.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   100] Training loss: 2.54285\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 200/5269 [07:31<3:09:08,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   200] Training loss: 2.51992\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 299/5269 [11:13<3:04:54,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   300] Training loss: 2.48902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 300/5269 [14:34<85:15:53, 61.77s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300 iterations --- Accuracy: 91.008381 % --- F1: 64.657438 % --- Loss: 3.342365 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 400/5269 [18:18<3:01:12,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   400] Training loss: 2.54086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5269 [22:02<2:56:46,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   500] Training loss: 2.50068\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 599/5269 [25:42<2:53:38,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   600] Training loss: 2.46213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 600/5269 [29:04<80:30:22, 62.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 iterations --- Accuracy: 91.222361 % --- F1: 59.326585 % --- Loss: 3.249007 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 700/5269 [32:49<2:50:18,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   700] Training loss: 2.48393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 800/5269 [36:32<2:46:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   800] Training loss: 2.43982\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 899/5269 [40:13<2:42:14,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch   900] Training loss: 2.48104\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 900/5269 [43:34<74:55:05, 61.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 iterations --- Accuracy: 90.651748 % --- F1: 64.762225 % --- Loss: 3.289484 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1000/5269 [47:20<2:39:47,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1000] Training loss: 2.45700\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1100/5269 [51:03<2:35:16,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1100] Training loss: 2.48085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1199/5269 [54:44<2:31:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1200] Training loss: 2.42725\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1200/5269 [58:05<70:02:20, 61.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 iterations --- Accuracy: 91.213445 % --- F1: 64.922584 % --- Loss: 3.268110 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1300/5269 [1:01:48<2:28:09,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1300] Training loss: 2.48481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1400/5269 [1:05:32<2:23:55,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1400] Training loss: 2.44902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1499/5269 [1:09:16<2:20:16,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1500] Training loss: 2.41398\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1500/5269 [1:12:37<64:35:44, 61.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1500 iterations --- Accuracy: 91.008381 % --- F1: 65.609548 % --- Loss: 3.390665 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1600/5269 [1:16:21<2:16:55,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1600] Training loss: 2.38055\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1700/5269 [1:20:04<2:12:53,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1700] Training loss: 2.44932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1799/5269 [1:23:45<2:09:14,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1800] Training loss: 2.39880\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1800/5269 [1:27:06<59:24:14, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 iterations --- Accuracy: 90.816690 % --- F1: 65.261383 % --- Loss: 3.232681 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1900/5269 [1:30:49<2:05:35,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  1900] Training loss: 2.41971\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2000/5269 [1:34:33<2:01:30,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2000] Training loss: 2.37320\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2099/5269 [1:38:14<1:57:52,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2100] Training loss: 2.42901\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2100/5269 [1:41:35<54:19:24, 61.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2100 iterations --- Accuracy: 91.418509 % --- F1: 65.107848 % --- Loss: 3.180166 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2200/5269 [1:45:18<1:54:19,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2200] Training loss: 2.37221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2300/5269 [1:49:01<1:50:44,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2300] Training loss: 2.37779\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2399/5269 [1:52:42<1:47:14,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2400] Training loss: 2.38885\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2400/5269 [1:56:03<49:09:16, 61.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 iterations --- Accuracy: 90.914765 % --- F1: 64.970780 % --- Loss: 3.221183 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2500/5269 [1:59:46<1:43:26,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2500] Training loss: 2.40193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2600/5269 [2:03:30<1:39:33,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2600] Training loss: 2.41140\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2699/5269 [2:07:14<1:36:21,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2700] Training loss: 2.39260\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2700/5269 [2:10:34<44:01:05, 61.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 iterations --- Accuracy: 91.405136 % --- F1: 65.583720 % --- Loss: 3.247399 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2800/5269 [2:14:17<1:31:55,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2800] Training loss: 2.36627\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2900/5269 [2:18:00<1:27:30,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  2900] Training loss: 2.31025\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2999/5269 [2:21:40<1:24:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3000] Training loss: 2.37464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3000/5269 [2:25:00<38:51:26, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 iterations --- Accuracy: 91.886591 % --- F1: 65.840841 % --- Loss: 3.182055 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3100/5269 [2:28:43<1:20:35,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3100] Training loss: 2.38521\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3200/5269 [2:32:26<1:16:46,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3200] Training loss: 2.35030\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3299/5269 [2:36:06<1:13:04,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3300] Training loss: 2.31219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3300/5269 [2:39:27<33:42:57, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3300 iterations --- Accuracy: 91.792974 % --- F1: 67.060297 % --- Loss: 3.242974 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3400/5269 [2:43:11<1:09:35,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3400] Training loss: 2.39137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3500/5269 [2:46:55<1:05:50,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3500] Training loss: 2.33418\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3599/5269 [2:50:36<1:02:03,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3600] Training loss: 2.34065\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3600/5269 [2:53:56<28:35:54, 61.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 iterations --- Accuracy: 91.717190 % --- F1: 63.725107 % --- Loss: 3.127354 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3700/5269 [2:57:42<58:19,  2.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3700] Training loss: 2.34566\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3800/5269 [3:01:25<54:49,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3800] Training loss: 2.33851\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3899/5269 [3:05:06<50:55,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  3900] Training loss: 2.28932\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3900/5269 [3:08:26<23:26:47, 61.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3900 iterations --- Accuracy: 91.775143 % --- F1: 67.059454 % --- Loss: 3.153967 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4000/5269 [3:12:10<47:10,  2.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4000] Training loss: 2.30400\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4100/5269 [3:15:53<43:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4100] Training loss: 2.29220\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4199/5269 [3:19:33<39:43,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4200] Training loss: 2.26919\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4200/5269 [3:22:54<18:18:34, 61.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 iterations --- Accuracy: 91.944544 % --- F1: 65.162907 % --- Loss: 3.126486 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4300/5269 [3:26:37<35:54,  2.22s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4300] Training loss: 2.26135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 4400/5269 [3:30:22<32:13,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4400] Training loss: 2.28529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4499/5269 [3:34:03<28:32,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4500] Training loss: 2.27695\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4500/5269 [3:37:24<13:10:26, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 iterations --- Accuracy: 91.703816 % --- F1: 65.746365 % --- Loss: 3.101076 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4600/5269 [3:41:07<25:01,  2.24s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4600] Training loss: 2.29460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4700/5269 [3:44:50<21:09,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4700] Training loss: 2.30502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4799/5269 [3:48:32<17:23,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4800] Training loss: 2.26440\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4800/5269 [3:51:52<8:01:42, 61.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 iterations --- Accuracy: 91.645863 % --- F1: 66.972154 % --- Loss: 3.178334 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4900/5269 [3:55:34<13:41,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  4900] Training loss: 2.25965\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5000/5269 [3:59:20<09:59,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  5000] Training loss: 2.26589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5099/5269 [4:03:02<06:18,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  5100] Training loss: 2.27927\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5100/5269 [4:06:23<2:54:30, 61.96s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5100 iterations --- Accuracy: 91.151034 % --- F1: 68.050861 % --- Loss: 3.100561 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 5200/5269 [4:10:08<02:34,  2.24s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1, Batch  5200] Training loss: 2.26571\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5270it [4:12:42,  2.88s/it]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END EPOCH 1 --- Accuracy: 91.712732 % --- F1: 64.570231 % ---Loss: 3.056045\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5269 [03:43<3:12:25,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   100] Training loss: 2.23658\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 200/5269 [07:25<3:08:22,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   200] Training loss: 2.25718\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 299/5269 [11:08<3:04:45,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   300] Training loss: 2.20964\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 300/5269 [14:28<85:05:15, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "600 iterations --- Accuracy: 92.064907 % --- F1: 66.963623 % --- Loss: 3.049550 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 400/5269 [18:11<3:00:34,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   400] Training loss: 2.23905\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5269 [21:54<2:56:52,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   500] Training loss: 2.22935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 599/5269 [25:35<2:53:24,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   600] Training loss: 2.21966\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 600/5269 [28:55<79:58:45, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1200 iterations --- Accuracy: 92.109486 % --- F1: 66.553288 % --- Loss: 3.064562 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 700/5269 [32:39<2:49:22,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   700] Training loss: 2.25223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 800/5269 [36:21<2:45:52,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   800] Training loss: 2.23952\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 899/5269 [40:02<2:42:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch   900] Training loss: 2.21525\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 900/5269 [43:22<74:50:05, 61.66s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 iterations --- Accuracy: 91.485378 % --- F1: 68.973359 % --- Loss: 3.056854 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1000/5269 [47:05<2:39:05,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1000] Training loss: 2.18249\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1100/5269 [50:49<2:34:31,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1100] Training loss: 2.22394\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1199/5269 [54:29<2:30:59,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1200] Training loss: 2.17721\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1200/5269 [57:51<70:05:31, 62.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2400 iterations --- Accuracy: 91.654779 % --- F1: 68.249661 % --- Loss: 3.095834 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1300/5269 [1:01:34<2:27:36,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1300] Training loss: 2.18967\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1400/5269 [1:05:16<2:22:54,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1400] Training loss: 2.23902\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1499/5269 [1:08:57<2:19:35,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1500] Training loss: 2.20342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1500/5269 [1:12:17<64:29:36, 61.60s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000 iterations --- Accuracy: 91.980207 % --- F1: 67.972227 % --- Loss: 3.047851 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1600/5269 [1:15:59<2:16:05,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1600] Training loss: 2.22886\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1700/5269 [1:19:45<2:12:17,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1700] Training loss: 2.23203\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1799/5269 [1:23:27<2:08:19,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1800] Training loss: 2.25524\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1800/5269 [1:26:49<59:42:56, 61.97s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 iterations --- Accuracy: 91.917796 % --- F1: 66.910020 % --- Loss: 3.030694 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1900/5269 [1:30:33<2:05:27,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  1900] Training loss: 2.21781\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2000/5269 [1:34:17<2:01:39,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2000] Training loss: 2.15086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2099/5269 [1:37:58<1:58:11,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2100] Training loss: 2.24292\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2100/5269 [1:41:18<54:16:58, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4200 iterations --- Accuracy: 92.252140 % --- F1: 68.027962 % --- Loss: 3.030168 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2200/5269 [1:45:02<1:54:12,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2200] Training loss: 2.15601\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2300/5269 [1:48:46<1:51:07,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2300] Training loss: 2.14114\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2399/5269 [1:52:27<1:46:42,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2400] Training loss: 2.19670\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2400/5269 [1:55:48<49:09:01, 61.67s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4800 iterations --- Accuracy: 91.788516 % --- F1: 69.462865 % --- Loss: 3.067619 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2500/5269 [1:59:31<1:43:21,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2500] Training loss: 2.15075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2600/5269 [2:03:14<1:38:53,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2600] Training loss: 2.18001\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2699/5269 [2:06:55<1:35:51,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2700] Training loss: 2.15897\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2700/5269 [2:10:16<43:59:21, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 iterations --- Accuracy: 92.047076 % --- F1: 68.085868 % --- Loss: 2.973866 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2800/5269 [2:13:59<1:32:54,  2.26s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2800] Training loss: 2.18246\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2900/5269 [2:17:43<1:28:38,  2.25s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  2900] Training loss: 2.15436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2999/5269 [2:21:24<1:24:12,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3000] Training loss: 2.13972\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3000/5269 [2:24:44<38:51:10, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6000 iterations --- Accuracy: 92.229850 % --- F1: 65.423527 % --- Loss: 2.979200 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3100/5269 [2:28:28<1:21:14,  2.25s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3100] Training loss: 2.13757\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 61%|██████    | 3200/5269 [2:32:11<1:16:34,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3200] Training loss: 2.17613\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3299/5269 [2:35:53<1:13:16,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3300] Training loss: 2.17723\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 3300/5269 [2:39:12<33:38:15, 61.50s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6600 iterations --- Accuracy: 92.127318 % --- F1: 68.225981 % --- Loss: 3.069283 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 65%|██████▍   | 3400/5269 [2:42:57<1:09:28,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3400] Training loss: 2.15033\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 66%|██████▋   | 3500/5269 [2:46:39<1:05:41,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3500] Training loss: 2.14793\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3599/5269 [2:50:21<1:01:40,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3600] Training loss: 2.11748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 68%|██████▊   | 3600/5269 [2:53:42<28:36:08, 61.69s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 iterations --- Accuracy: 92.310093 % --- F1: 68.073293 % --- Loss: 3.002037 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 3700/5269 [2:57:26<58:19,  2.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3700] Training loss: 2.17714\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 3800/5269 [3:01:10<54:32,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3800] Training loss: 2.12416\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3899/5269 [3:04:51<50:58,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  3900] Training loss: 2.16356\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 3900/5269 [3:08:11<23:26:17, 61.63s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7800 iterations --- Accuracy: 91.703816 % --- F1: 68.853556 % --- Loss: 2.982321 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 76%|███████▌  | 4000/5269 [3:11:57<47:10,  2.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4000] Training loss: 2.15138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 4100/5269 [3:15:42<43:21,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4100] Training loss: 2.13254\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4199/5269 [3:19:23<39:51,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4200] Training loss: 2.12698\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|███████▉  | 4200/5269 [3:22:45<18:24:45, 62.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8400 iterations --- Accuracy: 92.501783 % --- F1: 68.204159 % --- Loss: 2.975178 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 4300/5269 [3:26:27<35:48,  2.22s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4300] Training loss: 2.12399\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 84%|████████▎ | 4400/5269 [3:30:10<32:16,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4400] Training loss: 2.11213\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4499/5269 [3:33:51<28:28,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4500] Training loss: 2.10929\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▌ | 4500/5269 [3:37:15<13:22:11, 62.59s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 iterations --- Accuracy: 92.100571 % --- F1: 68.857645 % --- Loss: 2.958749 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 4600/5269 [3:40:58<24:49,  2.23s/it]   "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4600] Training loss: 2.09941\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 4700/5269 [3:44:44<21:17,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4700] Training loss: 2.10472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4799/5269 [3:48:27<17:32,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4800] Training loss: 2.08935\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 91%|█████████ | 4800/5269 [3:51:50<8:06:46, 62.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9600 iterations --- Accuracy: 91.641405 % --- F1: 69.277405 % --- Loss: 2.933024 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 4900/5269 [3:55:33<13:39,  2.22s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  4900] Training loss: 2.11722\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 5000/5269 [3:59:16<09:58,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  5000] Training loss: 2.08387\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5099/5269 [4:03:01<06:20,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  5100] Training loss: 2.17621\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 5100/5269 [4:06:21<2:53:39, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10200 iterations --- Accuracy: 92.332382 % --- F1: 68.997837 % --- Loss: 2.935776 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 99%|█████████▊| 5200/5269 [4:10:04<02:33,  2.23s/it]  "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 2, Batch  5200] Training loss: 2.13195\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5270it [4:12:38,  2.88s/it]                          \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "END EPOCH 2 --- Accuracy: 92.354672 % --- F1: 69.270740 % ---Loss: 3.007961\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|▏         | 100/5269 [03:43<3:11:27,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   100] Training loss: 2.14512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  4%|▍         | 200/5269 [07:26<3:08:25,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   200] Training loss: 2.07940\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 299/5269 [11:07<3:04:44,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   300] Training loss: 2.07314\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  6%|▌         | 300/5269 [14:27<85:04:31, 61.64s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "900 iterations --- Accuracy: 92.751427 % --- F1: 70.154185 % --- Loss: 2.933124 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 400/5269 [18:11<3:04:17,  2.27s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   400] Training loss: 2.05611\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  9%|▉         | 500/5269 [21:57<2:57:51,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   500] Training loss: 2.10357\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 599/5269 [25:38<2:53:17,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   600] Training loss: 2.11354\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█▏        | 600/5269 [28:59<80:18:00, 61.91s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1800 iterations --- Accuracy: 92.363588 % --- F1: 70.541702 % --- Loss: 2.936171 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 700/5269 [32:43<2:50:08,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   700] Training loss: 2.08384\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 800/5269 [36:27<2:46:36,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   800] Training loss: 2.04219\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 899/5269 [40:08<2:41:50,  2.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch   900] Training loss: 2.07750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 900/5269 [43:28<74:40:38, 61.53s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2700 iterations --- Accuracy: 92.448288 % --- F1: 68.253373 % --- Loss: 2.909823 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 19%|█▉        | 1000/5269 [47:12<2:39:36,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1000] Training loss: 2.09243\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 1100/5269 [50:58<2:45:44,  2.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1100] Training loss: 2.07762\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1199/5269 [54:40<2:32:09,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1200] Training loss: 2.06086\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 1200/5269 [58:01<69:45:01, 61.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3600 iterations --- Accuracy: 92.635521 % --- F1: 69.654666 % --- Loss: 2.890525 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▍       | 1300/5269 [1:01:44<2:28:15,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1300] Training loss: 2.10735\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 1400/5269 [1:05:30<2:46:36,  2.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1400] Training loss: 2.06035\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1499/5269 [1:09:11<2:20:09,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1500] Training loss: 2.10215\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 1500/5269 [1:12:35<65:37:07, 62.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4500 iterations --- Accuracy: 92.524073 % --- F1: 69.614061 % --- Loss: 2.951760 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1600/5269 [1:16:18<2:16:18,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1600] Training loss: 2.07401\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 32%|███▏      | 1700/5269 [1:20:03<2:27:40,  2.48s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1700] Training loss: 2.06589\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1799/5269 [1:23:43<2:08:52,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1800] Training loss: 2.06528\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 34%|███▍      | 1800/5269 [1:27:04<59:40:17, 61.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5400 iterations --- Accuracy: 92.073823 % --- F1: 70.247657 % --- Loss: 2.960834 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 1900/5269 [1:30:49<2:05:18,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  1900] Training loss: 2.03645\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 2000/5269 [1:34:32<2:01:25,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2000] Training loss: 2.02534\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2099/5269 [1:38:13<1:57:47,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2100] Training loss: 2.04428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|███▉      | 2100/5269 [1:41:34<54:28:51, 61.89s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6300 iterations --- Accuracy: 92.501783 % --- F1: 71.277322 % --- Loss: 2.886565 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 42%|████▏     | 2200/5269 [1:45:17<1:54:35,  2.24s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2200] Training loss: 2.06488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 2300/5269 [1:49:00<1:50:57,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2300] Training loss: 2.04143\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2399/5269 [1:52:41<1:46:35,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2400] Training loss: 2.04857\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 2400/5269 [1:56:01<49:07:49, 61.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7200 iterations --- Accuracy: 92.359130 % --- F1: 70.958997 % --- Loss: 2.889404 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 2500/5269 [1:59:44<1:42:51,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2500] Training loss: 2.01015\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▉     | 2600/5269 [2:03:28<1:39:02,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2600] Training loss: 2.02257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2699/5269 [2:07:09<1:35:18,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2700] Training loss: 2.04632\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 2700/5269 [2:10:30<44:15:09, 62.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8100 iterations --- Accuracy: 92.622147 % --- F1: 69.346175 % --- Loss: 2.883556 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 2800/5269 [2:14:14<1:31:51,  2.23s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2800] Training loss: 2.04586\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 55%|█████▌    | 2900/5269 [2:17:57<1:28:22,  2.24s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  2900] Training loss: 2.03875\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 2999/5269 [2:21:38<1:24:14,  2.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  3000] Training loss: 2.01411\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 3000/5269 [2:24:58<38:46:19, 61.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000 iterations --- Accuracy: 92.653352 % --- F1: 68.000000 % --- Loss: 2.902757 \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3100/5269 [2:28:41<1:20:25,  2.22s/it] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 3, Batch  3100] Training loss: 2.08165\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 3124/5269 [2:29:35<1:42:42,  2.87s/it]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m model\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[1;32m      5\u001b[0m running_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.0\u001b[39m\n\u001b[0;32m----> 6\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtqdm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtqdm\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43menumerate\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43msegmentation_gt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstack\u001b[49m\u001b[43m(\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mx\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43my\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mr\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfloat\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/tqdm/std.py:1181\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1178\u001b[0m time \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_time\n\u001b[1;32m   1180\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1181\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m   1182\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n\u001b[1;32m   1183\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Update and possibly print the progressbar.\u001b[39;49;00m\n\u001b[1;32m   1184\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: does not call self.update(1) for speed optimisation.\u001b[39;49;00m\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:631\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    628\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    629\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    630\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 631\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    632\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    633\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[1;32m    635\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/torch/utils/data/dataloader.py:675\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    673\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m    674\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m--> 675\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m    676\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[1;32m    677\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[0;34m(self, possibly_batched_index)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/torch/utils/data/_utils/fetch.py:51\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     49\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[1;32m     50\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 51\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n\u001b[1;32m     52\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[0;32mIn[2], line 16\u001b[0m, in \u001b[0;36mBallDataset.__getitem__\u001b[0;34m(self, idx)\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m     15\u001b[0m     row \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdf\u001b[38;5;241m.\u001b[39miloc[idx]\n\u001b[0;32m---> 16\u001b[0m     img \u001b[38;5;241m=\u001b[39m \u001b[43mImage\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpath\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimages_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mimage\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mL\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# Convert to grayscale\u001b[39;00m\n\u001b[1;32m     17\u001b[0m     patch_dim \u001b[38;5;241m=\u001b[39m (row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_x\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_y\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_x\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m], row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_y\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m+\u001b[39m row[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpatch_size\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m     18\u001b[0m     patch \u001b[38;5;241m=\u001b[39m img\u001b[38;5;241m.\u001b[39mcrop(patch_dim)\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/PIL/Image.py:941\u001b[0m, in \u001b[0;36mImage.convert\u001b[0;34m(self, mode, matrix, dither, palette, colors)\u001b[0m\n\u001b[1;32m    889\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mconvert\u001b[39m(\n\u001b[1;32m    890\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    891\u001b[0m     mode: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    895\u001b[0m     colors: \u001b[38;5;28mint\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m256\u001b[39m,\n\u001b[1;32m    896\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Image:\n\u001b[1;32m    897\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    898\u001b[0m \u001b[38;5;124;03m    Returns a converted copy of this image. For the \"P\" mode, this\u001b[39;00m\n\u001b[1;32m    899\u001b[0m \u001b[38;5;124;03m    method translates pixels through the palette.  If mode is\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    938\u001b[0m \u001b[38;5;124;03m    :returns: An :py:class:`~PIL.Image.Image` object.\u001b[39;00m\n\u001b[1;32m    939\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 941\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    943\u001b[0m     has_transparency \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtransparency\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minfo\n\u001b[1;32m    944\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m mode \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mP\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    945\u001b[0m         \u001b[38;5;66;03m# determine default mode\u001b[39;00m\n",
      "File \u001b[0;32m/media/raid0/.conda/lib/python3.11/site-packages/PIL/ImageFile.py:291\u001b[0m, in \u001b[0;36mImageFile.load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    288\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mOSError\u001b[39;00m(msg)\n\u001b[1;32m    290\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m s\n\u001b[0;32m--> 291\u001b[0m n, err_code \u001b[38;5;241m=\u001b[39m \u001b[43mdecoder\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m n \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m    293\u001b[0m     \u001b[38;5;28;01mbreak\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "detection_weight = 5\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for i, data in tqdm.tqdm(enumerate(data_loader, 0), total=len(dataset)//batch_size):\n",
    "        inputs, labels = data[0].to(device), data[1].float().to(device)\n",
    "        segmentation_gt = torch.stack((data[2][\"x\"], data[2][\"y\"], data[2][\"r\"]), dim=1).to(device).to(torch.float)\n",
    "\n",
    "        classification_mask = labels == 1.\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        classification, segmentation = model(inputs)\n",
    "        loss = classification_criterion(classification, labels.unsqueeze(1))\n",
    "\n",
    "        loss = detection_weight*segmentation_criterion(segmentation[classification_mask], segmentation_gt[classification_mask]) + loss\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "\n",
    "        if (i+1) % log_rate == 0: \n",
    "            print('[Epoch %d, Batch %5d] Training loss: %.5f' %\n",
    "                  (epoch + 1, i + 1, running_loss / log_rate))\n",
    "            running_loss = 0.0\n",
    "    \n",
    "        if (i + 1) % eval_rate == 0:\n",
    "            val_loss, accuracy, f1 = validate(model, detection_weight, best_loss)\n",
    "            print('%d iterations --- Accuracy: %f %% --- F1: %f %% --- Loss: %f ' % ((epoch + 1) * (i + 1), accuracy, f1, val_loss))\n",
    "\n",
    "    val_loss, accuracy, f1 = validate(model, detection_weight, best_loss)\n",
    "    print('END EPOCH %d --- Accuracy: %f %% --- F1: %f %% ---Loss: %f' % ((epoch + 1), accuracy, f1, val_loss))\n",
    "\n",
    "\n",
    "print('Finished Training')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END EPOCH 1 ---  --- "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x300 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "PATH = \"strong.pt\"\n",
    "\n",
    "model.load_state_dict(torch.load(PATH))\n",
    "model.to(torch.device(\"cpu\"))\n",
    "\n",
    "num_images = 5\n",
    "threshold = 0.5\n",
    "sample = next(iter(validation_loader))\n",
    "\n",
    "preds = model(sample[0])\n",
    "\n",
    "detection, segmentation = preds\n",
    "\n",
    "ig, axes = plt.subplots(2, num_images, figsize=(num_images * 3, 3))\n",
    "\n",
    "\n",
    "for i in range(num_images):\n",
    "    axes[0, i].imshow(sample[0][i][0], cmap='gray')\n",
    "    if detection[i] > threshold:\n",
    "        c = Circle((segmentation[i][0].item(),segmentation[i][1].item()), segmentation[i][2].item())\n",
    "        c.set_facecolor((1.0,0.,0.,0.4))\n",
    "        axes[0, i].add_patch(c)\n",
    "    axes[0, i].axis('off')\n",
    "    axes[1, i].text(0.5, 0, f'Contains Ball Predicted: {detection[i].item()> threshold}\\n Ground Truth: {sample[1][i]}', horizontalalignment='center')  # Add text under each image\n",
    "    axes[1, i].axis('off')  # Turn off axis for text\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1000 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1000/1000 [00:09<00:00, 107.12it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.008591138362884521"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "import onnx \n",
    "import onnxruntime as ort\n",
    "import os\n",
    "import tqdm\n",
    "def measure_inference_time(model, input_size=(1, 1, 32, 32), device='cpu', num_runs=1000):\n",
    "    input_tensor = torch.randn(input_size)\n",
    "    model.to(device)\n",
    "    \n",
    "    torch.onnx.export(model, input_tensor, \"tmp.onnx\", export_params=True, opset_version=12)\n",
    "\n",
    "    onnx_model = onnx.load(\"tmp.onnx\")\n",
    "    onnx.checker.check_model(onnx_model)\n",
    "\n",
    "    onnx_input = {onnx_model.graph.input[0].name: input_tensor.detach().cpu().numpy()}\n",
    "    \n",
    "    onnx_session = ort.InferenceSession('tmp.onnx')\n",
    "\n",
    "    total_time = 0\n",
    "    for _ in tqdm.tqdm(range(num_runs)):\n",
    "        start_time = time.time()\n",
    "        onnx_session.run(None, onnx_input)\n",
    "        total_time += time.time() - start_time\n",
    "\n",
    "    avg_time = total_time / num_runs\n",
    "    os.remove(\"tmp.onnx\")\n",
    "    return avg_time\n",
    "\n",
    "measure_inference_time(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "dummy_input = torch.randn(1, 1, 32, 32)\n",
    "\n",
    "torch.onnx.export(model, dummy_input, \"model.onnx\", \n",
    "                  input_names=['input'], output_names=['output_classification', 'output_detection'], \n",
    "                  dynamic_axes={'input': {0: 'batch_size'}, 'output_classification': {0: 'batch_size'}, 'output_detection': {0: 'batch_size'}})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting onnxruntime\n",
      "  Downloading onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl.metadata (4.3 kB)\n",
      "Collecting coloredlogs (from onnxruntime)\n",
      "  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl.metadata (12 kB)\n",
      "Collecting flatbuffers (from onnxruntime)\n",
      "  Using cached flatbuffers-24.3.25-py2.py3-none-any.whl.metadata (850 bytes)\n",
      "Requirement already satisfied: numpy>=1.24.2 in /media/raid0/.conda/lib/python3.11/site-packages (from onnxruntime) (1.26.4)\n",
      "Requirement already satisfied: packaging in /media/raid0/.conda/lib/python3.11/site-packages (from onnxruntime) (24.0)\n",
      "Requirement already satisfied: protobuf in /media/raid0/.conda/lib/python3.11/site-packages (from onnxruntime) (5.27.1)\n",
      "Requirement already satisfied: sympy in /media/raid0/.conda/lib/python3.11/site-packages (from onnxruntime) (1.12)\n",
      "Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n",
      "  Downloading humanfriendly-10.0-py2.py3-none-any.whl.metadata (9.2 kB)\n",
      "Requirement already satisfied: mpmath>=0.19 in /media/raid0/.conda/lib/python3.11/site-packages (from sympy->onnxruntime) (1.3.0)\n",
      "Downloading onnxruntime-1.18.0-cp311-cp311-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m10.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hUsing cached flatbuffers-24.3.25-py2.py3-none-any.whl (26 kB)\n",
      "Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m19.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: flatbuffers, humanfriendly, coloredlogs, onnxruntime\n",
      "Successfully installed coloredlogs-15.0.1 flatbuffers-24.3.25 humanfriendly-10.0 onnxruntime-1.18.0\n"
     ]
    }
   ],
   "source": [
    "!pip install onnxruntime"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
